{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17ca9a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install kagglehub\n",
    "#!pip install imblearn \n",
    "#!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9e77f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import imblearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df1234bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n"
     ]
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"henrysue/online-shoppers-intention\")\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f832416c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (12330, 18)\n",
      "Dataset Preview:\n",
      "   Administrative  Administrative_Duration  Informational  \\\n",
      "0               0                      0.0              0   \n",
      "1               0                      0.0              0   \n",
      "2               0                      0.0              0   \n",
      "3               0                      0.0              0   \n",
      "4               0                      0.0              0   \n",
      "\n",
      "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
      "0                     0.0               1                 0.000000   \n",
      "1                     0.0               2                64.000000   \n",
      "2                     0.0               1                 0.000000   \n",
      "3                     0.0               2                 2.666667   \n",
      "4                     0.0              10               627.500000   \n",
      "\n",
      "   BounceRates  ExitRates  PageValues  SpecialDay Month  OperatingSystems  \\\n",
      "0         0.20       0.20         0.0         0.0   Feb                 1   \n",
      "1         0.00       0.10         0.0         0.0   Feb                 2   \n",
      "2         0.20       0.20         0.0         0.0   Feb                 4   \n",
      "3         0.05       0.14         0.0         0.0   Feb                 3   \n",
      "4         0.02       0.05         0.0         0.0   Feb                 3   \n",
      "\n",
      "   Browser  Region  TrafficType        VisitorType  Weekend  Revenue  \n",
      "0        1       1            1  Returning_Visitor    False    False  \n",
      "1        2       1            2  Returning_Visitor    False    False  \n",
      "2        1       9            3  Returning_Visitor    False    False  \n",
      "3        2       2            4  Returning_Visitor    False    False  \n",
      "4        3       1            4  Returning_Visitor     True    False  \n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(f\"{path}/online_shoppers_intention.csv\")\n",
    "print(\"Dataset Shape:\", dataset.shape)\n",
    "print(\"Dataset Preview:\")\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a03aa95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      " Administrative             0\n",
      "Administrative_Duration    0\n",
      "Informational              0\n",
      "Informational_Duration     0\n",
      "ProductRelated             0\n",
      "ProductRelated_Duration    0\n",
      "BounceRates                0\n",
      "ExitRates                  0\n",
      "PageValues                 0\n",
      "SpecialDay                 0\n",
      "Month                      0\n",
      "OperatingSystems           0\n",
      "Browser                    0\n",
      "Region                     0\n",
      "TrafficType                0\n",
      "VisitorType                0\n",
      "Weekend                    0\n",
      "Revenue                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# checking for missing values\n",
    "print(\"Missing Values:\\n\", dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "660c3862",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder() # encoding our data\n",
    "for column in dataset.select_dtypes(include=['object']).columns:\n",
    "    dataset[column] = label_encoder.fit_transform(dataset[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49ed8f71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        False\n",
      "1        False\n",
      "2        False\n",
      "3        False\n",
      "4        False\n",
      "         ...  \n",
      "12325    False\n",
      "12326    False\n",
      "12327    False\n",
      "12328    False\n",
      "12329    False\n",
      "Name: Revenue, Length: 12330, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "X = dataset.drop(columns=['Revenue']) # establishing the target,y, vs the predictor cols\n",
    "y = dataset['Revenue']\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb377b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# splitting into train data and test data\n",
    "# test is 30% of db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "516921c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GaussianNB()  # predefined gaussian naive bayes model from sklearn lib\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30bb6327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85\n",
      "Precision: 0.52\n",
      "Recall: 0.53\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test) # predict\n",
    "\n",
    "\n",
    "# performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f\"Recall: {recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f01b924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# func for calculating mean and variance\n",
    "def calculate_mean_variance(data):\n",
    "    return np.mean(data, axis=0), np.var(data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30c4998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian probability density function\n",
    "# naive bayes assumes normal distribution of data\n",
    "def gaussian_pdf(x, mean, var):\n",
    "    return (1 / np.sqrt(2 * np.pi * var)) * np.exp(-(x - mean) ** 2 / (2 * var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dde2708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predction funct using bayes algorithm\n",
    "def predict(X, threshold=0.7):\n",
    "    predictions = []\n",
    "    for i in range(len(X)):\n",
    "        \n",
    "        # likelihood for each class\n",
    "        likelihood_false = np.log(p_false)\n",
    "        likelihood_true = np.log(p_true)\n",
    "        for j in range(X.shape[1]):  # shape[1] for the number of features\n",
    "            likelihood_false += np.log(gaussian_pdf(X[i, j], mean_false[j], var_false[j]))\n",
    "            likelihood_true += np.log(gaussian_pdf(X[i, j], mean_true[j], var_true[j]))\n",
    "        \n",
    "        # posterior probabilities (normalized)\n",
    "        total_likelihood = np.exp(likelihood_false) + np.exp(likelihood_true)\n",
    "        posterior_false = np.exp(likelihood_false) / total_likelihood\n",
    "        posterior_true = np.exp(likelihood_true) / total_likelihood\n",
    "        \n",
    "        # threshold to decide the class\n",
    "        if posterior_true >= threshold:\n",
    "            predictions.append(1)  # \"True\" prediction\n",
    "        else:\n",
    "            predictions.append(0)  # \"False\"\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b986398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing \n",
    "# encoding categorical features \n",
    "start = time.time()\n",
    "label_encoder = LabelEncoder()\n",
    "for column in dataset.select_dtypes(include=['object']).columns:\n",
    "    dataset[column] = label_encoder.fit_transform(dataset[column])\n",
    "\n",
    "# features and target\n",
    "X = dataset.drop(columns=['Revenue'])\n",
    "y = dataset['Revenue']\n",
    "\n",
    "# SelectKBest to select the top 'k' features\n",
    "k_best = SelectKBest(score_func=f_classif, k=3)\n",
    "X_new = k_best.fit_transform(X, y)\n",
    "\n",
    "# scaling the best k features obtained before\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_new)\n",
    "\n",
    "# split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "214cf558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE for oversampling, the data is imbalanced, class True in minority in the target var\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Separate data by class (after oversampling)\n",
    "X_train_false = X_train_res[y_train_res == 0]\n",
    "X_train_true = X_train_res[y_train_res == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aafa12ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction part\n",
    "# calculating prior probabilities with class weight adjustment\n",
    "# adjusting the priors (inversely proportional to class frequency)\n",
    "class_imbalance_factor = len(y_train_res) / (2 * np.bincount(y_train_res))\n",
    "p_false = class_imbalance_factor[0] / (class_imbalance_factor[0] + class_imbalance_factor[1])\n",
    "p_true = class_imbalance_factor[1] / (class_imbalance_factor[0] + class_imbalance_factor[1])\n",
    "\n",
    "# mean and variance for each class\n",
    "mean_false, var_false = calculate_mean_variance(X_train_false)\n",
    "mean_true, var_true = calculate_mean_variance(X_train_true)\n",
    "\n",
    "# predict \n",
    "y_pred_manual = predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d46119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a134af2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.87\n",
      "Precision: 0.60\n",
      "Recall: 0.55\n",
      "F1 Score: 0.57\n",
      "Exec time : 5.600075721740723 seconds\n"
     ]
    }
   ],
   "source": [
    "# performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred_manual)\n",
    "print(f\"Accuracy: {accuracy:.2f}\") #correct predictions\n",
    "precision = precision_score(y_test, y_pred_manual) \n",
    "print(f\"Precision: {precision:.2f}\") #tp/(tp+fp)\n",
    "recall = recall_score(y_test, y_pred_manual)\n",
    "print(f\"Recall: {recall:.2f}\") #tp/(tp+fn)\n",
    "f1 = f1_score(y_test, y_pred_manual) # harmonic mean bt precision and recall\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(\"Exec time : {} seconds\".format(time.time() - start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
